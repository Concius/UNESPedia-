# config.yaml
# ====================  PDF / RAG  ====================
pdf_processing:
  chunk_size: 512
  chunk_overlap: 50
  n_results: 10

# ----------------  EMBEDDING (multilingual)  ----------------
embedding:
  model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
  device: cpu          # cuda / cpu / mps
  normalize: true

# ====================  VECTOR STORES  ====================
vector_stores:
  ChromaDB:
    type: chroma
    path: chroma_db_store
    collection_name: artigos_academicos
  FAISS:
    type: faiss
    path: faiss_index.pkl

# ====================  LLM DEFAULTS  ====================
llm_defaults:
  temperature: 0.60
  top_p: 0.95
  top_k: 40
  max_output_tokens: 2048

# ====================  LLM PROVIDERS  ====================
llm_providers:
  Gemini:
    api_key: SUA_CHAVE_API_GEMINI_AQUI
    model: gemini-1.5-flash
  OpenAI:
    api_key: SUA_CHAVE_API_OPENAI_AQUI
    model: gpt-4o
  Claude:
    api_key: SUA_CHAVE_API_CLAUDE_AQUI
    model: claude-sonnet-4-20250514
  Deepseek:
    api_key: SUA_CHAVE_API_DEEPSEEK_AQUI
    model: deepseek-chat
  Moonshot Kimi:
    api_key: SUA_CHAVE_API_MOONSHOT_AQUI
    model: moonshot-v1-8k

# ====================  PRESETS  ====================
llm_presets:
  "ü§ñ Preciso":
    temperature: 0.20
    top_p: 0.90
    top_k: 20
  "üßë‚Äçüî¨ Equilibrado":
    temperature: 0.70
    top_p: 0.95
    top_k: 40
  "üé® Criativo":
    temperature: 1.20
    top_p: 0.98
    top_k: 50