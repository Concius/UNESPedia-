# researcher_profile.py

import streamlit as st
from llm_handler import gerar_resposta_com_llm
from collections import Counter
import re

def gerar_perfil_pesquisador(nome_pesquisador, lista_metadados, 
                             vector_store, provider_name, api_key, 
                             model_config, config_geracao):
    """
    Gera um perfil cientÃ­fico consolidado de um pesquisador.
    
    Args:
        nome_pesquisador: Nome do pesquisador
        lista_metadados: Lista de dicionÃ¡rios com metadados de TODOS os artigos
        vector_store: Vector store para buscar contexto adicional
        provider_name: Nome do provedor LLM
        api_key: Chave API
        model_config: ConfiguraÃ§Ã£o do modelo
        config_geracao: ParÃ¢metros de geraÃ§Ã£o
    
    Returns:
        str: Perfil formatado em Markdown
    """
    # ImportaÃ§Ã£o local para evitar circular imports
    try:
        from metadata_extractor import filtrar_artigos_por_autor
    except ImportError:
        from metadata_extractor_v2 import filtrar_artigos_por_autor
    
    # Filtrar apenas os artigos do pesquisador
    artigos_filtrados = filtrar_artigos_por_autor(
        lista_metadados, 
        nome_pesquisador, 
        threshold=0.7
    )
    
    if not artigos_filtrados:
        return f"âŒ Nenhum artigo encontrado para o pesquisador '{nome_pesquisador}'."
    
    # Construir contexto estruturado dos artigos
    contexto_estruturado = construir_contexto_artigos(
        nome_pesquisador, 
        artigos_filtrados, 
        vector_store
    )
    
    # Extrair palavras-chave por frequÃªncia (ajuda o LLM)
    keywords_sugeridas = extrair_palavras_chave_simples(artigos_filtrados)
    keywords_str = ", ".join(keywords_sugeridas) if keywords_sugeridas else "N/A"
    
    # Prompt especializado para geraÃ§Ã£o de perfil
    prompt_perfil = f"""
VocÃª Ã© um analista cientÃ­fico especializado em criar perfis de pesquisadores.

**IMPORTANTE:** VocÃª estÃ¡ analisando EXCLUSIVAMENTE a produÃ§Ã£o cientÃ­fica de **{nome_pesquisador}**.
NÃƒO confunda com outros autores que aparecem como coautores nos artigos.

**CONTEXTO:**
{contexto_estruturado}

**PALAVRAS-CHAVE DETECTADAS POR FREQUÃŠNCIA:**
{keywords_str}

**TAREFA:**
Gere um perfil cientÃ­fico completo de **{nome_pesquisador}** contendo:

## 1. Resumo da Linha de Pesquisa (200-300 palavras)
- Principais Ã¡reas de atuaÃ§Ã£o
- Foco metodolÃ³gico
- Abordagens preferenciais
- EvoluÃ§Ã£o temporal dos tÃ³picos (se identificÃ¡vel)

## 2. Principais ContribuiÃ§Ãµes CientÃ­ficas
Liste 3-5 contribuiÃ§Ãµes mais relevantes identificadas nos artigos.
Para cada contribuiÃ§Ã£o:
- DescriÃ§Ã£o breve (1-2 linhas)
- Artigo(s) correspondente(s)

## 3. Palavras-chave da Pesquisa
Identifique 10-15 palavras-chave/termos tÃ©cnicos mais frequentes e relevantes.
Use as palavras-chave detectadas acima como base, mas refine e complete a lista.
Ordene por relevÃ¢ncia/frequÃªncia.
Formato: palavra-chave1, palavra-chave2, palavra-chave3, ...

## 4. Colaboradores Frequentes
Liste atÃ© 5 coautores que aparecem em mÃºltiplos artigos (se houver).

## 5. AnÃ¡lise Temporal (se aplicÃ¡vel)
- Como a pesquisa evoluiu ao longo dos anos?
- MudanÃ§as de foco ou novas direÃ§Ãµes identificÃ¡veis?

**FORMATO DE SAÃDA:**
Use markdown com seÃ§Ãµes claras (## para tÃ­tulos).
Seja objetivo e baseie-se APENAS no conteÃºdo fornecido.
NÃ£o invente informaÃ§Ãµes.

**LEMBRE-SE:** Este perfil Ã© sobre **{nome_pesquisador}** especificamente, nÃ£o sobre os tÃ³picos gerais dos artigos.
"""

    # Gerar perfil usando LLM
    try:
        perfil = gerar_resposta_com_llm(
            provider_name=provider_name,
            api_key=api_key,
            model_config=model_config,
            contexto=contexto_estruturado,
            pergunta=prompt_perfil,
            historico_chat=[],  # Sem histÃ³rico, Ã© geraÃ§Ã£o standalone
            nomes_ficheiros=[a['fonte'] for a in artigos_filtrados],
            config_geracao=config_geracao
        )
        return perfil
    except Exception as e:
        # Fallback: perfil bÃ¡sico com keywords extraÃ­das
        st.warning(f"âš ï¸ Erro ao gerar perfil com LLM: {e}")
        st.info("ðŸ“Š Gerando perfil bÃ¡sico com anÃ¡lise estatÃ­stica...")
        
        perfil_fallback = f"""# Perfil CientÃ­fico de {nome_pesquisador}

**âš ï¸ Nota:** Este perfil foi gerado automaticamente por anÃ¡lise estatÃ­stica devido a erro na geraÃ§Ã£o via LLM.

## EstatÃ­sticas BÃ¡sicas
- **Total de artigos:** {len(artigos_filtrados)}
- **Anos de publicaÃ§Ã£o:** {min([a.get('ano', 9999) for a in artigos_filtrados if a.get('ano')])} - {max([a.get('ano', 0) for a in artigos_filtrados if a.get('ano')])}

## Palavras-chave Detectadas (por frequÃªncia)
{', '.join(keywords_sugeridas) if keywords_sugeridas else "Nenhuma palavra-chave detectada"}

## Artigos Analisados
"""
        for i, artigo in enumerate(artigos_filtrados, 1):
            perfil_fallback += f"\n{i}. **{artigo['titulo']}** ({artigo.get('ano', 'N/A')})\n"
        
        return perfil_fallback


def construir_contexto_artigos(nome_pesquisador, artigos_filtrados, vector_store):
    """
    ConstrÃ³i contexto estruturado dos artigos para o LLM.
    """
    contexto = f"# AnÃ¡lise da ProduÃ§Ã£o CientÃ­fica de {nome_pesquisador}\n\n"
    contexto += f"**Total de artigos analisados:** {len(artigos_filtrados)}\n\n"
    
    # Ordenar por ano (mais recente primeiro)
    artigos_ordenados = sorted(
        artigos_filtrados, 
        key=lambda x: x.get('ano', 0) or 0, 
        reverse=True
    )
    
    for idx, artigo in enumerate(artigos_ordenados, 1):
        contexto += f"\n## Artigo {idx}: {artigo['titulo']}\n"
        contexto += f"- **Autores:** {', '.join(artigo['autores'][:5])}"
        if len(artigo['autores']) > 5:
            contexto += f" (e outros {len(artigo['autores']) - 5})"
        contexto += "\n"
        
        if artigo.get('ano'):
            contexto += f"- **Ano:** {artigo['ano']}\n"
        
        # Verificar posiÃ§Ã£o do pesquisador
        try:
            posicao = next(
                i for i, autor in enumerate(artigo['autores']) 
                if nome_pesquisador.lower() in autor.lower()
            )
            if posicao == 0:
                contexto += f"- **PosiÃ§Ã£o do pesquisador:** Primeiro autor\n"
            else:
                contexto += f"- **PosiÃ§Ã£o do pesquisador:** {posicao + 1}Âº autor\n"
        except StopIteration:
            contexto += f"- **PosiÃ§Ã£o do pesquisador:** Coautor\n"
        
        # Abstract
        if artigo.get('abstract'):
            contexto += f"\n**Abstract:**\n{artigo['abstract'][:800]}\n"
        
        # Buscar contexto adicional do vector store
        if vector_store:
            try:
                resultados = vector_store.buscar(
                    query_texts=f"main contribution methodology results {artigo['titulo'][:50]}",
                    n_results=2,
                    where={"fonte": artigo['fonte']}
                )
                
                if resultados and resultados.get('documents') and resultados['documents'][0]:
                    contexto += f"\n**Trechos relevantes do artigo:**\n"
                    for doc in resultados['documents'][0][:2]:
                        contexto += f"- {doc[:200]}...\n"
            except Exception:
                pass  # Ignora erros na busca do vector store
        
        contexto += "\n" + "="*50 + "\n"
    
    return contexto


def extrair_palavras_chave_simples(artigos_filtrados):
    """
    ExtraÃ§Ã£o simples de palavras-chave por frequÃªncia (fallback).
    Usa caso o LLM falhe.
    """
    # Coletar todo o texto dos abstracts
    texto_completo = " ".join([
        artigo.get('abstract', '') for artigo in artigos_filtrados
    ])
    
    # Limpar e tokenizar
    texto_limpo = re.sub(r'[^\w\s]', ' ', texto_completo.lower())
    palavras = texto_limpo.split()
    
    # Remover stopwords bÃ¡sicas
    stopwords = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'been', 'be',
        'this', 'that', 'these', 'those', 'we', 'our', 'their', 'it', 'its',
        'de', 'da', 'do', 'das', 'dos', 'em', 'para', 'com', 'por', 'uma',
        'um', 'os', 'as', 'na', 'no', 'que', 'se', 'Ã©', 'ou', 'foi', 'sÃ£o',
        'can', 'using', 'used', 'based', 'paper', 'study', 'research', 'work',
        'approach', 'method', 'propose', 'show', 'result', 'found', 'abstract',
        'introduction', 'conclusion', 'keywords', 'references'
    }
    
    palavras_filtradas = [
        p for p in palavras 
        if len(p) > 3 and p not in stopwords
    ]
    
    # Contar frequÃªncias
    contador = Counter(palavras_filtradas)
    
    # Retornar top 15
    return [palavra for palavra, _ in contador.most_common(15)]